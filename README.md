# SOFTMAX-TILING

**This is the replication of the online softmax function that is used in [FlashAttention](https://arxiv.org/abs/2205.14135).**

The code was inspired by the medium article [ELI5: FlashAttention](https://gordicaleksa.medium.com/eli5-flash-attention-5c44017022ad) by [Aleksa GordiÄ‡](https://gordicaleksa.medium.com/).
Another [reference](https://courses.cs.washington.edu/courses/cse599m/23sp/notes/flashattn.pdf) that was quite useful in understanding the concept.

The code can be experimented by varying L (sequence length) and D (head dimension).

